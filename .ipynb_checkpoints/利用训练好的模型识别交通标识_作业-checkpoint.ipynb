{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../图片数据/logo.png\" alt=\"Header\" style=\"width: 800px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@Copyright (C): 2010-2019, Shenzhen Yahboom Tech  \n",
    "@Author: Malloy.Yuan  \n",
    "@Date: 2019-07-17 10:10:02  \n",
    "@LastEditors: Malloy.Yuan  \n",
    "@LastEditTime: 2019-09-17 17:54:19  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载训练模型\n",
    "我们通过运行'训练模型'把'采集数据'代码采集到的数据训练成了我们需要得到的避障模型之后,我们现在开始一步一步使用这个模型,实现避障的功能\n",
    "\n",
    "执行以下代码，初始化PyTorch模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "model = torchvision.models.alexnet(pretrained=False)\n",
    "model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，加载您上传的，已经通过pycharm训练过的``best_model.pth`` 的模型 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目前，模型权重计算位于CPU内存上，我们需要将模型通过'CUDA'转移到GPU上执行,执行下面的代码以使用到GPU。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预处理功能\n",
    "现在我们加载了模型，但有一个小问题，就是我们的摄像头的图像格式要与训练模型时的图像格式完全相同。要做到这一点，我们需要做一些预处理。分如下几个步骤：\n",
    "\n",
    "1. 从BGR转换为RGB模式\n",
    "2. 从HWC布局转换为CHW布局\n",
    "3. 使用与训练期间相同的参数进行标准化（我们的摄像机提供[0,255]范围内的值，并在[0,1]范围内训练加载的图像，因此我们需要缩放255.0\n",
    "4. 将数据从CPU内存传输到GPU内存\n",
    "5. 批量添加维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "mean = 255.0 * np.array([0.485, 0.456, 0.406])\n",
    "stdev = 255.0 * np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean, stdev)\n",
    "\n",
    "def preprocess(camera_value):\n",
    "    global device, normalize\n",
    "    x = camera_value\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.to(device)\n",
    "    x = x[None, ...]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们现在定义了我们的预处理功能，可以将图像从相机格式转换为神经网络输入的格式。\n",
    "\n",
    "现在，让我们显示我们的摄像头。 你现在应该对此非常熟悉。 我们还将创建五个滑块，用于显示机器人位于不同场景的概率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b070926b34e4c8b809581a65dbd04d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import traitlets\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "#camera = Camera.instance(width=224, height=224)\n",
    "camera = Camera.instance(width=224, height=224, fps=20)\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)\n",
    "free_slider = widgets.FloatSlider(description='free', min=0.0, max=1.0, orientation='vertical')\n",
    "left_slider = widgets.FloatSlider(description='left', min=0.0, max=1.0, orientation='vertical')\n",
    "right_slider = widgets.FloatSlider(description='right', min=0.0, max=1.0, orientation='vertical')\n",
    "slowly_slider = widgets.FloatSlider(description='slowly', min=0.0, max=1.0, orientation='vertical')\n",
    "stop_slider = widgets.FloatSlider(description='stop', min=0.0, max=1.0, orientation='vertical')\n",
    "\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "display(widgets.HBox([image, free_slider,left_slider,right_slider,slowly_slider,stop_slider]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建驱动电机的robot实例."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建驱动RBG、蜂鸣器实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Carrier board is not from a Jetson Developer Kit.\n",
      "WARNNIG: Jetson.GPIO library has not been verified with this carrier board,\n",
      "WARNING: and in fact is unlikely to work correctly.\n",
      "/usr/local/lib/python3.6/dist-packages/Jetson/GPIO/gpio.py:352: RuntimeWarning: This channel is already in use, continuing anyway. Use GPIO.setwarnings(False) to disable warnings\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from RGB_Lib import Programing_RGB\n",
    "RGB = Programing_RGB()\n",
    "import RPi.GPIO as GPIO\n",
    "BEEP_pin = 6 \n",
    "GPIO.setmode(GPIO.BCM)\n",
    "# set pin as an output pin with optional initial state of HIGH\n",
    "GPIO.setup(BEEP_pin, GPIO.OUT, initial=GPIO.LOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们创建一个函数，只要相机的值发生变化，就会调用该函数。 此功能将执行以下步骤\n",
    "\n",
    "1. 预处理相机图像\n",
    "2. 执行神经网络\n",
    "3. 通过对神经网络输出解码，编写相关程序实现后续动作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0860, 0.5471, 0.3054, 0.0141, 0.0474], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "def update(change):\n",
    "    global free_slider, left_slider,right_slider,slowly_slider,stop_slider,robot\n",
    "    #fps = 0.0\n",
    "    t1 = time.time()\n",
    "    x = change['new'] \n",
    "    x = preprocess(x)\n",
    "    y = model(x)\n",
    "    \n",
    "    # we apply the `softmax` function to normalize the output vector so it sums to 1 (which makes it a probability distribution)\n",
    "    y = F.softmax(y, dim=1)\n",
    "    y = y[0]\n",
    "    print(y)\n",
    "    free_slider.value = float(y[0])\n",
    "    left_slider.value = float(y[1])\n",
    "    right_slider.value = float(y[2])\n",
    "    slowly_slider.value = float(y[3])\n",
    "    stop_slider.value = float(y[4])\n",
    "    \n",
    "    max_index = torch.argmax(y)\n",
    "    \n",
    "    if max_index == 0:\n",
    "        robot.forward(1)\n",
    "        GPIO.output(BEEP_pin, GPIO.LOW)\n",
    "        RGB.Set_BreathSColor_RGB(2)\n",
    "        RGB.Set_BreathSSpeed_RGB(3)\n",
    "        RGB.Set_BreathSLight_RGB()\n",
    "    if max_index == 1:\n",
    "        GPIO.output(BEEP_pin, GPIO.LOW)\n",
    "        robot.left(0.75)\n",
    "        RGB.OFF_ALL_RGB()\n",
    "        RGB.Set_An_RGB(9, 0xFF, 0x00, 0x00)\n",
    "    if max_index == 2:\n",
    "        GPIO.output(BEEP_pin, GPIO.LOW)\n",
    "        robot.right(0.75)\n",
    "        RGB.OFF_ALL_RGB()\n",
    "        RGB.Set_An_RGB(4, 0xFF, 0x00, 0x00)\n",
    "    if max_index == 3:\n",
    "        robot.left_motor.value = 0.5\n",
    "        robot.right_motor.value = 0.5\n",
    "        RGB.Set_All_RGB(0xFF, 0x00, 0x00)\n",
    "        GPIO.output(BEEP_pin, GPIO.HIGH)\n",
    "    \n",
    "    if max_index == 4:\n",
    "        GPIO.output(BEEP_pin, GPIO.LOW)\n",
    "        robot.stop()\n",
    "        RGB.Set_ChameleonLight_RGB()\n",
    "        RGB.OFF_ALL_RGB()\n",
    "        \n",
    "    time.sleep(0.001)\n",
    "        \n",
    "update({'new': camera.value})  # we call the function once to intialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们已经创建了神经网络执行功能，但现在我们需要将它附加到相机进行处理。\n",
    "\n",
    "我们用``observe`` 函数完成这个处理。\n",
    "\n",
    "提示：此代码将开始移动机器人！ 请确保你的Jetbot位于可移动地带,避免跌落损坏!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.observe(update, names='value')  # this attaches the 'update' function to the 'value' traitlet of our camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行完上面单元格代码块后，Jetbot就开始为每个检测到的照片生成新命令。 首先将机器人放在地上，看看它遇到不同场景时的反应。\n",
    "\n",
    "如果要停止此行为，可以通过执行以下代码来取消。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.unobserve(update, names='value')\n",
    "time.sleep(1)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也许你希望Jetbot在没有流式传输视频的情况下运行，这样会减少JetBot的运算负担。 执行如下代码，你可以取消摄像头的连接。\n",
    "只是不推流到浏览器上，但在Jetbot上摄像头仍然是工作状态中的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_link.unlink()  # don't stream to browser (will still run camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "又如果要继续在浏览器显示视频，请执行以下代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_link.link()  # stream to browser (wont run camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RGB.Set_An_RGB(4, 0xFF, 0x00, 0x00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPIO.output(BEEP_pin, GPIO.LOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPIO.output(BEEP_pin, GPIO.HIGH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Set_ChameleonLight_RGB() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-3ab3fff026d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mRGB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSet_ChameleonLight_RGB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Set_ChameleonLight_RGB() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
